{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1j8Z7DpTK1hTz4dqPlG0R5RCyOdIn4rgK",
      "authorship_tag": "ABX9TyM1ys2CIdB2lhC9wiJBckA8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dapopadev/project/blob/main/operaciones%20arrays%20%20pruebas%20estad%C3%ADsticas(t-student%20y%20p%20value).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.GENERAMOS UN NOTEBOOK"
      ],
      "metadata": {
        "id": "w6VAWlUShxzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.INSTALAMOS PYSPARK"
      ],
      "metadata": {
        "id": "4inZuogvOiO0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcFi2lkdYNOe",
        "outputId": "1e61c35e-1d75-4a70-c854-d1df9de5ab9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.1.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.1-py2.py3-none-any.whl size=311285387 sha256=8c3cad55868ce1542189eb5972e3f3f6835d0b80cb2c4ef285328334bdb30186\n",
            "  Stored in directory: /root/.cache/pip/wheels/0d/77/a3/ff2f74cc9ab41f8f594dabf0579c2a7c6de920d584206e0834\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CREAMOS LA SESIÓN PYSPARK"
      ],
      "metadata": {
        "id": "zsnC84ynOunP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "zOkLso66YesZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "wm0mJtxqYpxx"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.DISEÑAMOS LA UNIDAD PERSONAL DE GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "yCmYraCsO1aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount(\"/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kbJPlo9Y1VH",
        "outputId": "4cb1383f-442b-482f-f89c-9881a15ad844"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark=SparkSession.builder.appName(\"my_app\").getOrCreate()"
      ],
      "metadata": {
        "id": "ae6Q6GLDZSde"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.CARGAMOS EL ARCHIVO CVS_STOCKS_2021 EN UN DATAFRAME"
      ],
      "metadata": {
        "id": "mQ08XD7yO9d_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=spark.read.option(\"Header\",True).csv(\"/drive/MyDrive/CSV_stocks_2021.csv\")"
      ],
      "metadata": {
        "id": "Xl630khEZqlw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.FILTRAMOS LAS FILAS QUE CORRESPONDEN CON EL VALOR HON DE LA COLUMNA TICKER"
      ],
      "metadata": {
        "id": "J-OQp_gKPJZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hon=df.filter(df.ticker=='HON')"
      ],
      "metadata": {
        "id": "19DhZ670djZE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*RENOMBRAMOS LA COLUMNA OPEN PARA NO PERDER DATOS"
      ],
      "metadata": {
        "id": "T6qXadC8PevU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_hon=df_hon.withColumnRenamed('open','open_hon')"
      ],
      "metadata": {
        "id": "PtnDRDM9UNOI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_hon.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gizUJjKwV4Jp",
        "outputId": "abadaafc-4b5c-466a-8ae0-3490c0daa8c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------------+------------------+------------------+------------------+-------+---------+------------+----------+---+\n",
            "|ticker|          open_hon|              high|               low|             close| volume|dividends|stock splits|      date|ccy|\n",
            "+------+------------------+------------------+------------------+------------------+-------+---------+------------+----------+---+\n",
            "|   HON|207.45501408335315|209.42141232111007|206.14735745495346|209.12644958496094|1406400|      0.0|           0|2020-12-31|USD|\n",
            "|   HON|209.26409612607986|209.43123817541044| 202.8929700588177| 204.4562530517578|2328900|      0.0|           0|2021-01-04|USD|\n",
            "|   HON|203.50255708426138| 206.6586329757187|203.50255708426138|204.95770263671875|2172100|      0.0|           0|2021-01-05|USD|\n",
            "|   HON|205.93106042557045|210.38495140642195|205.71475541084416|   208.69384765625|2747900|      0.0|           0|2021-01-06|USD|\n",
            "|   HON|209.31327369732284|210.41445198270796|207.25839100319203|209.03797912597656|2057300|      0.0|           0|2021-01-07|USD|\n",
            "|   HON|209.22477804904162|209.82453011896777| 204.1809617069155|206.50131225585938|3278900|      0.0|           0|2021-01-08|USD|\n",
            "|   HON|  204.613559972612|206.09818517407587|204.33826543197534|204.85935974121094|2938900|      0.0|           0|2021-01-11|USD|\n",
            "|   HON|  204.367783872409| 205.9605617566175|201.81145998195402| 205.3706512451172|2498800|      0.0|           0|2021-01-12|USD|\n",
            "|   HON|  204.780710862364| 205.1149949615185|202.93229172186355|203.54188537597656|2145100|      0.0|           0|2021-01-13|USD|\n",
            "|   HON|204.54474810663825|206.25552005813464|203.69919622290033| 205.1051788330078|3661500|      0.0|           0|2021-01-14|USD|\n",
            "|   HON|204.04330969253792|204.36776719848436|    201.7524539705|  202.509521484375|3887500|      0.0|           0|2021-01-15|USD|\n",
            "|   HON| 204.7414004554059|205.25265322179186| 202.9814655406593| 203.2862548828125|2656300|      0.0|           0|2021-01-19|USD|\n",
            "|   HON| 204.4267604669998|205.16415981146147|203.19776155956373|204.58407592773438|2452400|      0.0|           0|2021-01-20|USD|\n",
            "|   HON|203.38457127629206|204.31860744308085|201.65414621989987|201.78195190429688|2705100|      0.0|           0|2021-01-21|USD|\n",
            "|   HON| 200.8282604869766|201.02491232627204| 198.0064836217491|198.85203552246094|3502700|      0.0|           0|2021-01-22|USD|\n",
            "|   HON|197.95731446101044|199.15681863147958|196.73815710917054|198.47840881347656|4737700|      0.0|           0|2021-01-25|USD|\n",
            "|   HON|200.41529910872143|201.32968206461314|197.60334910836625| 197.6820068359375|2201900|      0.0|           0|2021-01-26|USD|\n",
            "|   HON|194.78159101389213|197.38706285147768|193.22813450230996|196.03025817871094|4108600|      0.0|           0|2021-01-27|USD|\n",
            "|   HON|197.24941031607628|201.89995313608185|196.27605275101863|199.43211364746094|3731700|      0.0|           0|2021-01-28|USD|\n",
            "|   HON| 193.2084624142251|197.56404251420506| 191.2814004531731|192.08761596679688|4635100|      0.0|           0|2021-01-29|USD|\n",
            "+------+------------------+------------------+------------------+------------------+-------+---------+------------+----------+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.CONVERTIMOS EL DATAFRAME SPARK A UNO PANDAS"
      ],
      "metadata": {
        "id": "mLxyWzlEPseQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uPumlvYyNTFN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "PaXu8ikyJ4ee"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pandas_hon_open=df_hon.toPandas()"
      ],
      "metadata": {
        "id": "3MF6zbWkUsQR"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.EXTRAEMOS LA COLUMNA 'OPEN' Y LA CONVERTIMOS EN UN ARRAY UNIDIMENSIONAL USANDO NUMPY"
      ],
      "metadata": {
        "id": "vO_yMK8HP7_u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hon_array=np.array(pandas_hon_open['open_hon']).ravel()"
      ],
      "metadata": {
        "id": "lOR819IrVOtB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.DIVIDIMOS EL ARRAY EN 2 PARA COMAPRAR 2 PEERIODOS"
      ],
      "metadata": {
        "id": "sGpMZaiBQYUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hon_array_split=np.array_split(hon_array,2)"
      ],
      "metadata": {
        "id": "yGqqzBr_KEHc"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hon_array_0=hon_array_split[0].astype(float)"
      ],
      "metadata": {
        "id": "0S5nOQ1cKdqp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hon_mean_0=np.mean(hon_array_0)"
      ],
      "metadata": {
        "id": "buLchrb5KtkF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hon_array_1=hon_array_split[1].astype(float)"
      ],
      "metadata": {
        "id": "T9sarQiMLE5C"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hon_mean_1=np.mean(hon_array_1)"
      ],
      "metadata": {
        "id": "3ozwBnFfLdsR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.APLICAMOS LA PRUEBA ESTADÍSTICA T DE STUDENT"
      ],
      "metadata": {
        "id": "emfplLUlQnmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats"
      ],
      "metadata": {
        "id": "Rnt8Ot32NmXl"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.ttest_ind(hon_array_0,hon_array_1,equal_var=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpU7qA7HLttS",
        "outputId": "5c4760d5-7a3d-4ba5-8e73-f455497b07b4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TtestResult(statistic=-5.175116593297485, pvalue=4.81611057993437e-07, df=239.70116425677583)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LA PRUEBA P-VALUE ES INFERIOR A 0.5 POR LO TANTO RECHAZAMOS LA HIPÓTESIS NULA\n",
        "EN CUANTO A LOS PERIODOS PROMEDIOS NO SE SI ME DA SOLO UNO PORQUE EL SPLIT NO SE HA EFECTUADO CORRECTAMENTE"
      ],
      "metadata": {
        "id": "C9kGhrqWSWBf"
      }
    }
  ]
}